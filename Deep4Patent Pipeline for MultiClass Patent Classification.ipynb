{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning based Pipeline with Multichannel Inputs for Patent Classification\n",
    "\n",
    "This notebook describes a deep learning pipeline for automatic patent classification with multichannel inputs.  A neural network model is trained with multichannel inputs namely embeddings of different segments of patent texts, and sparse linear\n",
    "input of different metadata. <br> <br>\n",
    "<img src=\"arch_0000.png\" height=\"600\" width=\"700\">\n",
    "\n",
    "<br>\n",
    "In this notebook the classification task is a multi-class classification. The basic outline is:  <br>  <br>\n",
    "\n",
    "- load patent dataset  <br>\n",
    "- apply preprocessing tasks  <br>\n",
    "- apply Tokenization process  <br>\n",
    "- Load a pretraines word embeddings model  <br>\n",
    "- prepare the embedding matrix for patent texts   <br>\n",
    "- concatenated deep layers <br>\n",
    "- train a deep neural network on the data  <br>\n",
    "- show the results  <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Loading patent dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TI</th>\n",
       "      <th>AB</th>\n",
       "      <th>TECHF</th>\n",
       "      <th>BACKG</th>\n",
       "      <th>SUMM</th>\n",
       "      <th>CLMS</th>\n",
       "      <th>ICM</th>\n",
       "      <th>AY</th>\n",
       "      <th>IPC</th>\n",
       "      <th>REF</th>\n",
       "      <th>PA</th>\n",
       "      <th>INV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EP2000017943-0</td>\n",
       "      <td>Recognition code, particularly for a disk-shap...</td>\n",
       "      <td>A recognition code, particularly for a disk-li...</td>\n",
       "      <td>[1] The present invention relates to a recogni...</td>\n",
       "      <td>[2] It is known that identification labels, ad...</td>\n",
       "      <td>[5] The aim of the present invention is to ove...</td>\n",
       "      <td></td>\n",
       "      <td>G06K0019-06</td>\n",
       "      <td>2000</td>\n",
       "      <td>[G06K0019-06, G06K0007-10]</td>\n",
       "      <td></td>\n",
       "      <td>[Video System Italia S.r.l.]</td>\n",
       "      <td>[Tassello  Stefano]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EP2003016733-0</td>\n",
       "      <td>Optical pickup apparatus for recording/reprodu...</td>\n",
       "      <td>An optical pickup apparatus for reproducing in...</td>\n",
       "      <td>[1] The present invention relates to an optica...</td>\n",
       "      <td>BACKGROUND OF THE INVENTION   [2] Recently, as...</td>\n",
       "      <td>SUMMARY OF THE INVENTION[11] An object of the ...</td>\n",
       "      <td>['An optical pickup apparatus for recording an...</td>\n",
       "      <td>G11B0007-135</td>\n",
       "      <td>2000</td>\n",
       "      <td>[G11B0007-135, G11B0007-125]</td>\n",
       "      <td></td>\n",
       "      <td>[Konica Minolta Opto  Inc.]</td>\n",
       "      <td>[Arai  Norikazu, Kojima  Toshiyuki, Kiriki  To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EP2011009984-0</td>\n",
       "      <td>Large capacity data sales mediation system, se...</td>\n",
       "      <td>An animation data sales mediation method, an a...</td>\n",
       "      <td>[1] The present invention relates to large cap...</td>\n",
       "      <td>BACKGROUND OF THE INVENTION   Description of t...</td>\n",
       "      <td>SUMMARY OF THE INVENTION[20] The present inven...</td>\n",
       "      <td>['A large capacity data sales mediation system...</td>\n",
       "      <td>G07F0017-16</td>\n",
       "      <td>2001</td>\n",
       "      <td>[G07F0017-16, G06Q0030-06, G06Q0020-10, G06Q00...</td>\n",
       "      <td>[JPHEI033290B, JPHEI08235759B, JPHEI10334048B,...</td>\n",
       "      <td>[NEC Corporation]</td>\n",
       "      <td>[Maeda Koji]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCT1997010546-0</td>\n",
       "      <td>BRIDGE FOR A CLIENT-SERVER ENVIRONMENT</td>\n",
       "      <td>A software bridge (300) is introduced between ...</td>\n",
       "      <td>1 BRIDGE FOR A CLIENT-SERVER ENVIRONMENT  Fiel...</td>\n",
       "      <td>Background of the Invention Overview of Object...</td>\n",
       "      <td>45 Disclosure of the Invention Accordingly the...</td>\n",
       "      <td>['1. A bridge (300) for use between a client (...</td>\n",
       "      <td>G06F009-46</td>\n",
       "      <td>1996</td>\n",
       "      <td>[G06F009-46, G06F009-44, G06F0009-44, G06F0009...</td>\n",
       "      <td></td>\n",
       "      <td>[INTERNATIONAL BUSINESS MACHINES CORPORATION, ...</td>\n",
       "      <td>[COLYER  ADRIAN  MARK]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PCT1998021641-0</td>\n",
       "      <td>PROCESSOR HAVING SECTIONS OPERATING AT DIFFERE...</td>\n",
       "      <td>A processor (250) including a first execution ...</td>\n",
       "      <td>PROCESSOR HAVING SECTIONS OPERATING AT DIFFERE...</td>\n",
       "      <td>Background of the Prior Art Fig. 1 illustrates...</td>\n",
       "      <td>SUMMARY OF THE INVENTION The invention provide...</td>\n",
       "      <td></td>\n",
       "      <td>G06F001-32</td>\n",
       "      <td>1997</td>\n",
       "      <td>[G06F001-32, G06F0001-08, G06F0009-30, G06F000...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[SAGER DAVID J, FLETCHER THOMAS D, HINTON GLEN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID                                                 TI  \\\n",
       "0   EP2000017943-0  Recognition code, particularly for a disk-shap...   \n",
       "1   EP2003016733-0  Optical pickup apparatus for recording/reprodu...   \n",
       "2   EP2011009984-0  Large capacity data sales mediation system, se...   \n",
       "3  PCT1997010546-0             BRIDGE FOR A CLIENT-SERVER ENVIRONMENT   \n",
       "4  PCT1998021641-0  PROCESSOR HAVING SECTIONS OPERATING AT DIFFERE...   \n",
       "\n",
       "                                                  AB  \\\n",
       "0  A recognition code, particularly for a disk-li...   \n",
       "1  An optical pickup apparatus for reproducing in...   \n",
       "2  An animation data sales mediation method, an a...   \n",
       "3  A software bridge (300) is introduced between ...   \n",
       "4  A processor (250) including a first execution ...   \n",
       "\n",
       "                                               TECHF  \\\n",
       "0  [1] The present invention relates to a recogni...   \n",
       "1  [1] The present invention relates to an optica...   \n",
       "2  [1] The present invention relates to large cap...   \n",
       "3  1 BRIDGE FOR A CLIENT-SERVER ENVIRONMENT  Fiel...   \n",
       "4  PROCESSOR HAVING SECTIONS OPERATING AT DIFFERE...   \n",
       "\n",
       "                                               BACKG  \\\n",
       "0  [2] It is known that identification labels, ad...   \n",
       "1  BACKGROUND OF THE INVENTION   [2] Recently, as...   \n",
       "2  BACKGROUND OF THE INVENTION   Description of t...   \n",
       "3  Background of the Invention Overview of Object...   \n",
       "4  Background of the Prior Art Fig. 1 illustrates...   \n",
       "\n",
       "                                                SUMM  \\\n",
       "0  [5] The aim of the present invention is to ove...   \n",
       "1  SUMMARY OF THE INVENTION[11] An object of the ...   \n",
       "2  SUMMARY OF THE INVENTION[20] The present inven...   \n",
       "3  45 Disclosure of the Invention Accordingly the...   \n",
       "4  SUMMARY OF THE INVENTION The invention provide...   \n",
       "\n",
       "                                                CLMS           ICM    AY  \\\n",
       "0                                                      G06K0019-06  2000   \n",
       "1  ['An optical pickup apparatus for recording an...  G11B0007-135  2000   \n",
       "2  ['A large capacity data sales mediation system...   G07F0017-16  2001   \n",
       "3  ['1. A bridge (300) for use between a client (...    G06F009-46  1996   \n",
       "4                                                       G06F001-32  1997   \n",
       "\n",
       "                                                 IPC  \\\n",
       "0                         [G06K0019-06, G06K0007-10]   \n",
       "1                       [G11B0007-135, G11B0007-125]   \n",
       "2  [G07F0017-16, G06Q0030-06, G06Q0020-10, G06Q00...   \n",
       "3  [G06F009-46, G06F009-44, G06F0009-44, G06F0009...   \n",
       "4  [G06F001-32, G06F0001-08, G06F0009-30, G06F000...   \n",
       "\n",
       "                                                 REF  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2  [JPHEI033290B, JPHEI08235759B, JPHEI10334048B,...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                                  PA  \\\n",
       "0                       [Video System Italia S.r.l.]   \n",
       "1                        [Konica Minolta Opto  Inc.]   \n",
       "2                                  [NEC Corporation]   \n",
       "3  [INTERNATIONAL BUSINESS MACHINES CORPORATION, ...   \n",
       "4                                                      \n",
       "\n",
       "                                                 INV  \n",
       "0                                [Tassello  Stefano]  \n",
       "1  [Arai  Norikazu, Kojima  Toshiyuki, Kiriki  To...  \n",
       "2                                       [Maeda Koji]  \n",
       "3                             [COLYER  ADRIAN  MARK]  \n",
       "4  [SAGER DAVID J, FLETCHER THOMAS D, HINTON GLEN...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../datasets/allITPatTextWith_Metadata.csv\",  encoding = \"ISO-8859-1\", error_bad_lines=False)\n",
    "df.columns =['ID','TI','AB','TECHF','BACKG','SUMM','CLMS','ICM','AY','IPC','REF','PA','INV']\n",
    "\n",
    "df.dropna(subset=['ICM'], inplace=True)\n",
    "\n",
    "\n",
    "df.fillna(value='', inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying preprocessing tasks on metadat of patent\n",
    "Converting the metatadata such as inventors and assignees of each patent into a python list, then apply preprocessing task on each element in the list in order to remove undesired tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.53 s, sys: 76.7 ms, total: 2.61 s\n",
      "Wall time: 2.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#preprocess of list fields\n",
    "#convert all IPCs in df into one list\n",
    "def toList(s):\n",
    "    \"\"\"\n",
    "    this method is to convert the list of IPCs in each row from a string to a python List\n",
    "    \"\"\"\n",
    "    s  = s.translate ({ord(c): \" \" for c in \"[]\"})\n",
    "    ss= []\n",
    "    for cls in s.strip().split(','):\n",
    "        ss.append(cls.strip())\n",
    "    return ss\n",
    "\n",
    "#apply toList method on all rows in the DF\n",
    "df['PA'] = df['PA'].map(lambda pa :   toList(pa))\n",
    "df['INV'] = df['INV'].map(lambda inv :   toList(inv))\n",
    "\n",
    "df.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.69 s, sys: 35.4 ms, total: 5.73 s\n",
      "Wall time: 5.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def metadataPreprocessing(input):\n",
    "    newInput=' '\n",
    "    for item in input:\n",
    "        item = item.translate ({ord(c): \" \" for c in \"!@#$%^&*()'[]{};:,./<>?\\|`~°=\\\"+\"})\n",
    "        itms=' '\n",
    "        for itm in item.split():\n",
    "            itms= itms +' '+itm.strip()\n",
    "        newInput = newInput + ' '+ itms.strip().replace(' ','_')\n",
    "    return newInput.strip()\n",
    "\n",
    "df['PA'] = df['PA'].map(lambda pa :   metadataPreprocessing(pa))\n",
    "df['INV'] = df['INV'].map(lambda inv :   metadataPreprocessing(inv))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Applying preprocessing tasks on texts of patent\n",
    "A simple preprocessing tasks such as tokenization, stopword removal, lemmatization, and converting letters into lower case are performed on each text section of each patent document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing \n",
    "standardStopwordFile = \"sources/stopwords/stopwords-all.txt\"\n",
    "\n",
    "#loading terms from a file to a set\n",
    "def get_terms_from_file(filePath):\n",
    "    terms = set(line.strip() for line in open(filePath))\n",
    "    return terms\n",
    "\n",
    "#remove undiserd terms\n",
    "def remove_terms(termSet, phrase):\n",
    "    newPhrase = \"\"\n",
    "    for term in phrase.split():\n",
    "        if term.strip() not in termSet and len(term.strip())>2:\n",
    "            newPhrase = newPhrase + \" \" + term.strip()\n",
    "\n",
    "\n",
    "\n",
    "def clean_texts(doc):\n",
    "    #Remove punctuation from texts\n",
    "    doc = doc.translate ({ord(c): ' ' for c in \"0123456789!@#$%^&*()'/[]{};:,./<>?\\|`~°=\\\"+\"})\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.lower().strip().split()\n",
    "    \n",
    "    # filter out stop words\n",
    "    stop_words = get_terms_from_file(standardStopwordFile)\n",
    "    #generalStopwords = get_terms_from_file(generalWordsFile)\n",
    "\n",
    "    \n",
    "    tokens = [w.strip('-')  for w in tokens if  w not in stop_words ]\n",
    "    # filter out short and long  tokens\n",
    "    output = [word for word in tokens if len(word.strip()) > 2 and len(word) < 30 ]\n",
    "    output = \" \".join(output)\n",
    "    #apply stemming\n",
    "    #output = stem_text(output)\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 271 µs, sys: 66 µs, total: 337 µs\n",
      "Wall time: 327 µs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TI</th>\n",
       "      <th>AB</th>\n",
       "      <th>TECHF</th>\n",
       "      <th>BACKG</th>\n",
       "      <th>SUMM</th>\n",
       "      <th>CLMS</th>\n",
       "      <th>ICM</th>\n",
       "      <th>AY</th>\n",
       "      <th>IPC</th>\n",
       "      <th>REF</th>\n",
       "      <th>PA</th>\n",
       "      <th>INV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EP2000017943-0</td>\n",
       "      <td>recognition disk-shaped medium</td>\n",
       "      <td>recognition disk-like medium multimedia applic...</td>\n",
       "      <td>recognition disk-shaped medium multimedia appl...</td>\n",
       "      <td>identification labels adapted interpreted opti...</td>\n",
       "      <td>overcome drawbacks noted conventional types id...</td>\n",
       "      <td></td>\n",
       "      <td>G06K0019-06</td>\n",
       "      <td>2000</td>\n",
       "      <td>[G06K0019-06, G06K0007-10]</td>\n",
       "      <td></td>\n",
       "      <td>Video_System_Italia_S_r_l</td>\n",
       "      <td>Tassello_Stefano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EP2003016733-0</td>\n",
       "      <td>optical pickup recording reproducing</td>\n",
       "      <td>optical pickup reproducing optical recording m...</td>\n",
       "      <td>optical pickup recording reproducing optical p...</td>\n",
       "      <td>recently practical short wavelength red laser ...</td>\n",
       "      <td>provide pickup recording reproducing optical r...</td>\n",
       "      <td>optical pickup recording reproducing optical m...</td>\n",
       "      <td>G11B0007-135</td>\n",
       "      <td>2000</td>\n",
       "      <td>[G11B0007-135, G11B0007-125]</td>\n",
       "      <td></td>\n",
       "      <td>Konica_Minolta_Opto_Inc</td>\n",
       "      <td>Arai_Norikazu_Kojima_Toshiyuki_Kiriki_Toshihik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EP2011009984-0</td>\n",
       "      <td>large capacity sales mediation</td>\n",
       "      <td>animation sales mediation animation sales medi...</td>\n",
       "      <td>large capacity sales large capacity sales medi...</td>\n",
       "      <td>recent years distributing music network rapidl...</td>\n",
       "      <td>implemented consideration problems provide ani...</td>\n",
       "      <td>large capacity sales mediation terminal large ...</td>\n",
       "      <td>G07F0017-16</td>\n",
       "      <td>2001</td>\n",
       "      <td>[G07F0017-16, G06Q0030-06, G06Q0020-10, G06Q00...</td>\n",
       "      <td>[JPHEI033290B, JPHEI08235759B, JPHEI10334048B,...</td>\n",
       "      <td>NEC_Corporation</td>\n",
       "      <td>Maeda_Koji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCT1997010546-0</td>\n",
       "      <td>bridge client-server environment</td>\n",
       "      <td>software bridge introduced client client-serve...</td>\n",
       "      <td>bridge client-server environment distributed c...</td>\n",
       "      <td>overview object-oriented programming developme...</td>\n",
       "      <td>bridge client distributed object-oriented brid...</td>\n",
       "      <td>bridge client distributed object-oriented brid...</td>\n",
       "      <td>G06F009-46</td>\n",
       "      <td>1996</td>\n",
       "      <td>[G06F009-46, G06F009-44, G06F0009-44, G06F0009...</td>\n",
       "      <td></td>\n",
       "      <td>INTERNATIONAL_BUSINESS_MACHINES_CORPORATION_CO...</td>\n",
       "      <td>COLYER_ADRIAN_MARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PCT1998021641-0</td>\n",
       "      <td>sections operating rates</td>\n",
       "      <td>core clocked perform operations clock frequenc...</td>\n",
       "      <td>sections operating rates high speed processors...</td>\n",
       "      <td>illustrates microprocessor microprocessor incl...</td>\n",
       "      <td>microprocessor levels sub-core clocked frequen...</td>\n",
       "      <td></td>\n",
       "      <td>G06F001-32</td>\n",
       "      <td>1997</td>\n",
       "      <td>[G06F001-32, G06F0001-08, G06F0009-30, G06F000...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SAGER_DAVID_J_FLETCHER_THOMAS_D_HINTON_GLENN_J...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID                                    TI  \\\n",
       "0   EP2000017943-0        recognition disk-shaped medium   \n",
       "1   EP2003016733-0  optical pickup recording reproducing   \n",
       "2   EP2011009984-0        large capacity sales mediation   \n",
       "3  PCT1997010546-0      bridge client-server environment   \n",
       "4  PCT1998021641-0              sections operating rates   \n",
       "\n",
       "                                                  AB  \\\n",
       "0  recognition disk-like medium multimedia applic...   \n",
       "1  optical pickup reproducing optical recording m...   \n",
       "2  animation sales mediation animation sales medi...   \n",
       "3  software bridge introduced client client-serve...   \n",
       "4  core clocked perform operations clock frequenc...   \n",
       "\n",
       "                                               TECHF  \\\n",
       "0  recognition disk-shaped medium multimedia appl...   \n",
       "1  optical pickup recording reproducing optical p...   \n",
       "2  large capacity sales large capacity sales medi...   \n",
       "3  bridge client-server environment distributed c...   \n",
       "4  sections operating rates high speed processors...   \n",
       "\n",
       "                                               BACKG  \\\n",
       "0  identification labels adapted interpreted opti...   \n",
       "1  recently practical short wavelength red laser ...   \n",
       "2  recent years distributing music network rapidl...   \n",
       "3  overview object-oriented programming developme...   \n",
       "4  illustrates microprocessor microprocessor incl...   \n",
       "\n",
       "                                                SUMM  \\\n",
       "0  overcome drawbacks noted conventional types id...   \n",
       "1  provide pickup recording reproducing optical r...   \n",
       "2  implemented consideration problems provide ani...   \n",
       "3  bridge client distributed object-oriented brid...   \n",
       "4  microprocessor levels sub-core clocked frequen...   \n",
       "\n",
       "                                                CLMS           ICM    AY  \\\n",
       "0                                                      G06K0019-06  2000   \n",
       "1  optical pickup recording reproducing optical m...  G11B0007-135  2000   \n",
       "2  large capacity sales mediation terminal large ...   G07F0017-16  2001   \n",
       "3  bridge client distributed object-oriented brid...    G06F009-46  1996   \n",
       "4                                                       G06F001-32  1997   \n",
       "\n",
       "                                                 IPC  \\\n",
       "0                         [G06K0019-06, G06K0007-10]   \n",
       "1                       [G11B0007-135, G11B0007-125]   \n",
       "2  [G07F0017-16, G06Q0030-06, G06Q0020-10, G06Q00...   \n",
       "3  [G06F009-46, G06F009-44, G06F0009-44, G06F0009...   \n",
       "4  [G06F001-32, G06F0001-08, G06F0009-30, G06F000...   \n",
       "\n",
       "                                                 REF  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2  [JPHEI033290B, JPHEI08235759B, JPHEI10334048B,...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                                  PA  \\\n",
       "0                          Video_System_Italia_S_r_l   \n",
       "1                            Konica_Minolta_Opto_Inc   \n",
       "2                                    NEC_Corporation   \n",
       "3  INTERNATIONAL_BUSINESS_MACHINES_CORPORATION_CO...   \n",
       "4                                                      \n",
       "\n",
       "                                                 INV  \n",
       "0                                   Tassello_Stefano  \n",
       "1  Arai_Norikazu_Kojima_Toshiyuki_Kiriki_Toshihik...  \n",
       "2                                         Maeda_Koji  \n",
       "3                                 COLYER_ADRIAN_MARK  \n",
       "4  SAGER_DAVID_J_FLETCHER_THOMAS_D_HINTON_GLENN_J...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#apply simple preprocessing on text\n",
    "df['TI'] = df['TI'].map(lambda line : clean_texts(line))\n",
    "df['AB'] = df['AB'].map(lambda line : clean_texts(line))\n",
    "df['TECHF'] = df['TECHF'].map(lambda line : clean_texts(line))\n",
    "df['BACKG'] = df['BACKG'].map(lambda line : clean_texts(line))\n",
    "df['SUMM'] = df['SUMM'].map(lambda line : clean_texts(line))\n",
    "df['CLMS'] = df['CLMS'].map(lambda line : clean_texts(line))\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Applying preprocessing tasks patent labels (main IPC codes)\n",
    "The main IPC codes is considered to be the labels for the patent documents. we only consider the subclass level of the IPC code. \n",
    "Each label/class has at least more than 500 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "581\n",
      "number of remaining documents in the dataset is:  403726\n",
      "Number of unique labels is:  42\n"
     ]
    }
   ],
   "source": [
    "#process the ICM codes and #related-patents\n",
    "df['ICM'] = df['ICM'].map(lambda icmCode : icmCode[:4])  \n",
    "\n",
    "df_ICMs = df.groupby(['ICM'])\n",
    "df_ICMs = df_ICMs.size().reset_index(name='Docs')\n",
    "\n",
    "print(len(df_ICMs.ICM.unique()))\n",
    "#filter out the rows with #docs less than N documents\n",
    "df_ICMOut =  df_ICMs[df_ICMs['Docs'] >= 500]\n",
    "\n",
    "#filter out rows of the original dataframe df accordding to df_ICMOut\n",
    "ICMList = df_ICMOut['ICM'].tolist()\n",
    "df = df[df.ICM.isin(ICMList)]\n",
    "\n",
    "icmCount = df_ICMs.count().tolist()[0]\n",
    "\n",
    "print( 'number of remaining documents in the dataset is: ',len(df))\n",
    "\n",
    "print('Number of unique labels is: ', len(df.ICM.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomly reorder a dataset by rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TI</th>\n",
       "      <th>AB</th>\n",
       "      <th>TECHF</th>\n",
       "      <th>BACKG</th>\n",
       "      <th>SUMM</th>\n",
       "      <th>CLMS</th>\n",
       "      <th>ICM</th>\n",
       "      <th>AY</th>\n",
       "      <th>IPC</th>\n",
       "      <th>REF</th>\n",
       "      <th>PA</th>\n",
       "      <th>INV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63956</th>\n",
       "      <td>PCT1997037347-0</td>\n",
       "      <td>closed loop servo focus</td>\n",
       "      <td>focus beam radiant energy detector beam output...</td>\n",
       "      <td>arrangements optical disc drives improved serv...</td>\n",
       "      <td>optical disc drives stored spiral concentric t...</td>\n",
       "      <td>primary extend operating range focus servo ope...</td>\n",
       "      <td></td>\n",
       "      <td>G11B</td>\n",
       "      <td>1997</td>\n",
       "      <td>[G11B007-09, G11B007-095, G11B0007-085, G11B00...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CESHKOVSKY_LUDWIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351416</th>\n",
       "      <td>PCT2017010778-0</td>\n",
       "      <td>based preventive maintenance large</td>\n",
       "      <td>based preventive maintenance large based preve...</td>\n",
       "      <td>refers predicting aging large operating detect...</td>\n",
       "      <td>sensor-based power generation makes rapid main...</td>\n",
       "      <td></td>\n",
       "      <td>collecting sensor sensors calculated slope fai...</td>\n",
       "      <td>G06Q</td>\n",
       "      <td>2016</td>\n",
       "      <td>[G06Q0050-10, G06Q0010-00]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>BAE_Suk_Joo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144383</th>\n",
       "      <td>PCT2017071542-0</td>\n",
       "      <td></td>\n",
       "      <td>acquiring configured acquire stream photograph...</td>\n",
       "      <td>limited</td>\n",
       "      <td>artwith development mobile phone mobile phone ...</td>\n",
       "      <td>outlined outlined non-is scope protection impr...</td>\n",
       "      <td>conversion configured chirp current frame carr...</td>\n",
       "      <td>H04N</td>\n",
       "      <td>2016</td>\n",
       "      <td>[H04N0005-243, G06T0005-50, H04N0005-217, H04N...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ZHU_Dezhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358317</th>\n",
       "      <td>PCT2012012538-0</td>\n",
       "      <td>memory cell</td>\n",
       "      <td>systems methods forming memory cells memory ce...</td>\n",
       "      <td></td>\n",
       "      <td>memory cell cross-references applications cfr ...</td>\n",
       "      <td>aspects ultra-thin sram cells layout topologie...</td>\n",
       "      <td></td>\n",
       "      <td>G06F</td>\n",
       "      <td>2011</td>\n",
       "      <td>[G06F0019-00]</td>\n",
       "      <td></td>\n",
       "      <td>UNIVERSITY_OF_VIRGINIA_PATENT_FOUNDATION_CALHO...</td>\n",
       "      <td>CALHOUN_Benton_H_MANN_Randy_W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363786</th>\n",
       "      <td>PCT2012015702-0</td>\n",
       "      <td>methods systems articles manufacture implement...</td>\n",
       "      <td>methods systems articles manufacture implement...</td>\n",
       "      <td></td>\n",
       "      <td>methods systems articles manufacture implement...</td>\n",
       "      <td>presents methods systems products implementing...</td>\n",
       "      <td>implemented implementing electronic design ele...</td>\n",
       "      <td>G06F</td>\n",
       "      <td>2011</td>\n",
       "      <td>[G06F0015-04, G06F0017-50]</td>\n",
       "      <td></td>\n",
       "      <td>CADENCE_DESIGN_SYSTEMS_INC_GOPALAKRISHNAN_Prak...</td>\n",
       "      <td>GOPALAKRISHNAN_Prakash_MCSHERRY_Michael_WHITE_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID                                                 TI  \\\n",
       "63956   PCT1997037347-0                            closed loop servo focus   \n",
       "351416  PCT2017010778-0                 based preventive maintenance large   \n",
       "144383  PCT2017071542-0                                                      \n",
       "358317  PCT2012012538-0                                        memory cell   \n",
       "363786  PCT2012015702-0  methods systems articles manufacture implement...   \n",
       "\n",
       "                                                       AB  \\\n",
       "63956   focus beam radiant energy detector beam output...   \n",
       "351416  based preventive maintenance large based preve...   \n",
       "144383  acquiring configured acquire stream photograph...   \n",
       "358317  systems methods forming memory cells memory ce...   \n",
       "363786  methods systems articles manufacture implement...   \n",
       "\n",
       "                                                    TECHF  \\\n",
       "63956   arrangements optical disc drives improved serv...   \n",
       "351416  refers predicting aging large operating detect...   \n",
       "144383                                            limited   \n",
       "358317                                                      \n",
       "363786                                                      \n",
       "\n",
       "                                                    BACKG  \\\n",
       "63956   optical disc drives stored spiral concentric t...   \n",
       "351416  sensor-based power generation makes rapid main...   \n",
       "144383  artwith development mobile phone mobile phone ...   \n",
       "358317  memory cell cross-references applications cfr ...   \n",
       "363786  methods systems articles manufacture implement...   \n",
       "\n",
       "                                                     SUMM  \\\n",
       "63956   primary extend operating range focus servo ope...   \n",
       "351416                                                      \n",
       "144383  outlined outlined non-is scope protection impr...   \n",
       "358317  aspects ultra-thin sram cells layout topologie...   \n",
       "363786  presents methods systems products implementing...   \n",
       "\n",
       "                                                     CLMS   ICM    AY  \\\n",
       "63956                                                      G11B  1997   \n",
       "351416  collecting sensor sensors calculated slope fai...  G06Q  2016   \n",
       "144383  conversion configured chirp current frame carr...  H04N  2016   \n",
       "358317                                                     G06F  2011   \n",
       "363786  implemented implementing electronic design ele...  G06F  2011   \n",
       "\n",
       "                                                      IPC REF  \\\n",
       "63956   [G11B007-09, G11B007-095, G11B0007-085, G11B00...       \n",
       "351416                         [G06Q0050-10, G06Q0010-00]       \n",
       "144383  [H04N0005-243, G06T0005-50, H04N0005-217, H04N...       \n",
       "358317                                      [G06F0019-00]       \n",
       "363786                         [G06F0015-04, G06F0017-50]       \n",
       "\n",
       "                                                       PA  \\\n",
       "63956                                                       \n",
       "351416                                                      \n",
       "144383                                                      \n",
       "358317  UNIVERSITY_OF_VIRGINIA_PATENT_FOUNDATION_CALHO...   \n",
       "363786  CADENCE_DESIGN_SYSTEMS_INC_GOPALAKRISHNAN_Prak...   \n",
       "\n",
       "                                                      INV  \n",
       "63956                                   CESHKOVSKY_LUDWIG  \n",
       "351416                                        BAE_Suk_Joo  \n",
       "144383                                          ZHU_Dezhi  \n",
       "358317                      CALHOUN_Benton_H_MANN_Randy_W  \n",
       "363786  GOPALAKRISHNAN_Prakash_MCSHERRY_Michael_WHITE_...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "df = shuffle(df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split the dataset into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(363353,)\n",
      "(40373,)\n"
     ]
    }
   ],
   "source": [
    "# lets take n% data as training and remaining m% for test.\n",
    "train_size = int(len(df) * .8)\n",
    "\n",
    "train_TI = df['TI'][:train_size]\n",
    "train_AB = df['AB'][:train_size]\n",
    "train_TECHF = df['TECHF'][:train_size]\n",
    "train_BACKG = df['BACKG'][:train_size]\n",
    "train_SUMM = df['SUMM'][:train_size]\n",
    "train_CLMS = df['CLMS'][:train_size]\n",
    "train_ICM= df['ICM'][:train_size]\n",
    "train_ID= df['ID'][:train_size]\n",
    "\n",
    "test_TI = df['TI'][train_size:]\n",
    "test_AB = df['AB'][train_size:]\n",
    "test_TECHF = df['TECHF'][train_size:]\n",
    "test_BACKG = df['BACKG'][train_size:]\n",
    "test_SUMM = df['SUMM'][train_size:]\n",
    "test_CLMS = df['CLMS'][train_size:]\n",
    "test_ICM = df['ICM'][train_size:]\n",
    "test_ID = df['ID'][train_size:]\n",
    "\n",
    "\n",
    "#metadata\n",
    "train_pa_series = df['PA'][:train_size]\n",
    "test_pa_series = df['PA'][train_size:]\n",
    "\n",
    "train_inv_series = df['INV'][:train_size]\n",
    "test_inv_series = df['INV'][train_size:]\n",
    "\n",
    "\n",
    "print(train_AB.shape)\n",
    "print(test_AB.shape)\n",
    "\n",
    "#free up some memory space\n",
    "#df.iloc[0:0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Applying tokenization process \n",
    "For texts of each segment, a Keras tokenization process is used for breaking the text into individual words, and  set the sequence length of each segment according to the length of each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot\n",
    "from sklearn.preprocessing import LabelBinarizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Keras tokenization on Metadata of patent(Inventors, Assignees), and convert the related text into One-hot that encodes a text into a list of word indexes of size n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 97734 words in PA\n",
      "Found 280346 words in INV\n"
     ]
    }
   ],
   "source": [
    "#PA\n",
    "pa_inv_vocab_size = 2000\n",
    "pa_tokenizer = Tokenizer(num_words=pa_inv_vocab_size,  filters='!\"#$%&()*+,./:;<=>?@[\\]^`{|}~', lower=True, split=' ', char_level=False, oov_token=None)\n",
    "pa_tokenizer.fit_on_texts(train_pa_series)\n",
    "train_pa_one_hot =pa_tokenizer.texts_to_matrix(train_pa_series)\n",
    "test_pa_one_hot =pa_tokenizer.texts_to_matrix(test_pa_series)\n",
    "\n",
    "\n",
    "#INV\n",
    "inv_tokenizer = Tokenizer(num_words=pa_inv_vocab_size,  filters='!\"#$%&()*+,./:;<=>?@[\\]^`{|}~', lower=True, split=' ', char_level=False, oov_token=None)\n",
    "inv_tokenizer.fit_on_texts(train_inv_series)\n",
    "train_inv_one_hot =inv_tokenizer.texts_to_matrix(train_inv_series)\n",
    "test_inv_one_hot =inv_tokenizer.texts_to_matrix(test_inv_series)\n",
    "\n",
    "\n",
    "print('Found %s words in PA' % len(pa_tokenizer.word_index))\n",
    "print('Found %s words in INV' % len(inv_tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Transform each text in Titles (train and test datasets) into a sequence of integers. <br>\n",
    "set the sequence length.<br>\n",
    "Pads sequences to the same length.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 s, sys: 69.9 ms, total: 11.1 s\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Title\n",
    "TI_tokenizer = Tokenizer(num_words=10000,  filters='!\"#$%&()*+,./:;<=>?@[\\]^`{|}~_', lower=True, split=' ', char_level=False, oov_token=None)\n",
    "TI_tokenizer.fit_on_texts(train_TI)\n",
    "encoded_train_TI = TI_tokenizer.texts_to_sequences(train_TI)\n",
    "encoded_test_TI = TI_tokenizer.texts_to_sequences(test_TI)\n",
    "#convert all sequences in a list into the same length\n",
    "TI_train = pad_sequences(encoded_train_TI,  maxlen=20, padding='post')\n",
    "TI_test = pad_sequences(encoded_test_TI,  maxlen=20, padding='post')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Transform each text in Abstrcat (train and test datasets) into a sequence of integers. <br>\n",
    "set the sequence length.<br>\n",
    "Pads sequences to the same length.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.3 s, sys: 377 ms, total: 30.7 s\n",
      "Wall time: 30.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Abstract\n",
    "AB_tokenizer = Tokenizer(num_words=50000,  filters='!\"#$%&()*+,./:;<=>?@[\\]^`{|}~_', lower=True, split=' ', char_level=False, oov_token=None)\n",
    "AB_tokenizer.fit_on_texts(train_AB)\n",
    "encoded_train_AB = AB_tokenizer.texts_to_sequences(train_AB)\n",
    "encoded_test_AB = AB_tokenizer.texts_to_sequences(test_AB)\n",
    "#convert all sequences in a list into the same length\n",
    "AB_train = pad_sequences(encoded_train_AB,  maxlen=100, padding='post')\n",
    "AB_test = pad_sequences(encoded_test_AB,  maxlen=100, padding='post')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Transform each text in Technical Field (train and test datasets) into a sequence of integers. <br>\n",
    "set the sequence length.<br>\n",
    "Pads sequences to the same length.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19 s, sys: 148 ms, total: 19.2 s\n",
      "Wall time: 19.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#TECHNICAL_FIELD\n",
    "TECHF_tokenizer = Tokenizer(num_words=20000,  filters='!\"#$%&()*+,./:;<=>?@[\\]^`{|}~_', lower=True, split=' ', char_level=False, oov_token=None)\n",
    "TECHF_tokenizer.fit_on_texts(train_TECHF)\n",
    "encoded_train_TECHF = TECHF_tokenizer.texts_to_sequences(train_TECHF)\n",
    "encoded_test_TECHF = TECHF_tokenizer.texts_to_sequences(test_TECHF)\n",
    "#convert all sequences in a list into the same length\n",
    "TECHF_train = pad_sequences(encoded_train_TECHF,  maxlen=30, padding='post')\n",
    "TECHF_test = pad_sequences(encoded_test_TECHF,  maxlen=30, padding='post')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Transform each text in Background (train and test datasets) into a sequence of integers. <br>\n",
    "set the sequence length.<br>\n",
    "Pads sequences to the same length.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 6s, sys: 1.12 s, total: 2min 7s\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#BACKGROUND\n",
    "BACKG_tokenizer = Tokenizer(num_words=50000,  filters='!\"#$%&()*+,./:;<=>?@[\\]^`{|}~_', lower=True, split=' ', char_level=False, oov_token=None)\n",
    "BACKG_tokenizer.fit_on_texts(train_BACKG)\n",
    "encoded_train_BACKG = BACKG_tokenizer.texts_to_sequences(train_BACKG)\n",
    "encoded_test_BACKG = BACKG_tokenizer.texts_to_sequences(test_BACKG)\n",
    "#convert all sequences in a list into the same length\n",
    "BACKG_train = pad_sequences(encoded_train_BACKG,  maxlen=100, padding='post')\n",
    "BACKG_test = pad_sequences(encoded_test_BACKG,  maxlen=100, padding='post')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Transform each text in Summary (train and test datasets) into a sequence of integers. <br>\n",
    "set the sequence length.<br>\n",
    "Pads sequences to the same length.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 46s, sys: 1.53 s, total: 2min 47s\n",
      "Wall time: 2min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#SUMMARY\n",
    "SUMM_tokenizer = Tokenizer(num_words=50000,  filters='!\"#$%&()*+,./:;<=>?@[\\]^`{|}~_', lower=True, split=' ', char_level=False, oov_token=None)\n",
    "SUMM_tokenizer.fit_on_texts(train_SUMM)\n",
    "encoded_train_SUMM = SUMM_tokenizer.texts_to_sequences(train_SUMM)\n",
    "encoded_test_SUMM = SUMM_tokenizer.texts_to_sequences(test_SUMM)\n",
    "#convert all sequences in a list into the same length\n",
    "SUMM_train = pad_sequences(encoded_train_SUMM,  maxlen=100, padding='post')\n",
    "SUMM_test = pad_sequences(encoded_test_SUMM,  maxlen=100, padding='post')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Transform each text in Independent Claim (train and test datasets) into a sequence of integers. <br>\n",
    "set the sequence length.<br>\n",
    "Pads sequences to the same length.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.3 s, sys: 792 ms, total: 41 s\n",
      "Wall time: 41.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#CLAIMS\n",
    "CLMS_tokenizer = Tokenizer(num_words=50000,  filters='!\"#$%&()*+,./:;<=>?@[\\]^`{|}~_', lower=True, split=' ', char_level=False, oov_token=None)\n",
    "CLMS_tokenizer.fit_on_texts(train_CLMS)\n",
    "encoded_train_CLMS = CLMS_tokenizer.texts_to_sequences(train_CLMS)\n",
    "encoded_test_CLMS = CLMS_tokenizer.texts_to_sequences(test_CLMS)\n",
    "#convert all sequences in a list into the same length\n",
    "CLMS_train = pad_sequences(encoded_train_CLMS,  maxlen=100, padding='post')\n",
    "CLMS_test = pad_sequences(encoded_test_CLMS,  maxlen=100, padding='post')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Representing the labels/classes in the numeric format by scikit-learn - LabelBinarizer class. <br>\n",
    "Convert 1-dimensional class arrays to n-dimensional(#classes) class matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.04 s, sys: 64.8 ms, total: 4.1 s\n",
      "Wall time: 4.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# \n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(train_ICM)\n",
    "y_train = encoder.transform(train_ICM)\n",
    "y_test = encoder.transform(test_ICM)\n",
    "\n",
    "#get the unique number of labels in the training set\n",
    "classesList = train_ICM.tolist()\n",
    "classesList =set(classesList)\n",
    "num_classes = len(classesList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  load the whole embeddings model into memory and get matrix\n",
    "We load a pre-trained word2vec word embedding model that was trained on five million patents (Titles and abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_embedding_model(filePath):\n",
    "    embeddings_index = dict()\n",
    "    f = open(filePath, encoding='utf8')\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "        \n",
    "    return embeddings_index\n",
    "\n",
    "def create_embedding_matrix(tokenizer, embeddings_index, vocab_size_embbs, dim_size):\n",
    "    embeddings_matrix = np.zeros((vocab_size_embbs, dim_size))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embeddings_matrix[i] = embedding_vector[0:dim_size]\n",
    "    \n",
    "    return embeddings_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Loading the whole embedding into memory and get matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 31s, sys: 2.75 s, total: 1min 34s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "embedding_index = load_embedding_model('../models/w2v/phrase/patWordPhrase2VecModel.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Creating TITLE embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 86.3 ms, sys: 57.9 ms, total: 144 ms\n",
      "Wall time: 143 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#vocab_size for embedding\n",
    "vocab_size_embb = len(TI_tokenizer.word_index) + 1\n",
    "\n",
    "TI_embeddings_matrix = create_embedding_matrix(TI_tokenizer,\n",
    "                                              embedding_index,\n",
    "                                              vocab_size_embb,\n",
    "                                              20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Creating ABSTRACT embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 235 ms, sys: 116 ms, total: 351 ms\n",
      "Wall time: 351 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#vocab_size for embedding\n",
    "vocab_size_embb = len(AB_tokenizer.word_index) + 1\n",
    "AB_embeddings_matrix = create_embedding_matrix(AB_tokenizer,\n",
    "                                              embedding_index,\n",
    "                                              vocab_size_embb,\n",
    "                                              100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating TECHNICAL_FIELD embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 161 ms, sys: 26 ms, total: 187 ms\n",
      "Wall time: 187 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#vocab_size for embedding\n",
    "vocab_size_embb = len(TECHF_tokenizer.word_index) + 1\n",
    "TECHF_embeddings_matrix = create_embedding_matrix(TECHF_tokenizer,\n",
    "                                              embedding_index,\n",
    "                                              vocab_size_embb,\n",
    "                                              30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating BACKGROUND embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#vocab_size for embedding\n",
    "vocab_size_embb = len(BACKG_tokenizer.word_index) + 1\n",
    "BACKG_embeddings_matrix = create_embedding_matrix(BACKG_tokenizer,\n",
    "                                              embedding_index,\n",
    "                                              vocab_size_embb,\n",
    "                                              100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating SUMMARY embeddings Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 540 ms, sys: 155 ms, total: 695 ms\n",
      "Wall time: 696 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#vocab_size for embedding\n",
    "vocab_size_embb = len(SUMM_tokenizer.word_index) + 1\n",
    "SUMM_embeddings_matrix = create_embedding_matrix(SUMM_tokenizer,\n",
    "                                              embedding_index,\n",
    "                                              vocab_size_embb,\n",
    "                                              100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating INDEPENDENT CLAIMS embeddings Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 187 ms, sys: 46.9 ms, total: 234 ms\n",
      "Wall time: 234 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#vocab_size for embedding\n",
    "vocab_size_embb = len(CLMS_tokenizer.word_index) + 1\n",
    "CLMS_embeddings_matrix = create_embedding_matrix(CLMS_tokenizer,\n",
    "                                              embedding_index,\n",
    "                                              vocab_size_embb,\n",
    "                                              100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Deep Layer for each Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Embedding, BatchNormalization, ELU, Concatenate\n",
    "from keras.layers import LSTM, Conv1D, MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.core import Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Creating LSTM deep layer for Title Embeddings<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.52 s, sys: 8.61 s, total: 13.1 s\n",
      "Wall time: 4.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#TITLE \n",
    "sequence_len =20\n",
    "dropout_pct =  0.3\n",
    "\n",
    "TI_embedding_layer_input = Input(shape=(sequence_len,), name='TI_embed_input')\n",
    "TI_embedding_layer = Embedding(input_dim=len(TI_tokenizer.word_index) + 1,\n",
    "                        output_dim=20, # Dimension of the dense embedding\n",
    "                        weights=[TI_embeddings_matrix],\n",
    "                        input_length=20)(TI_embedding_layer_input)\n",
    "\n",
    "lstm_size = 64\n",
    "TI_deep = LSTM(lstm_size,\n",
    "            dropout=dropout_pct,\n",
    "            recurrent_dropout=dropout_pct,\n",
    "            return_sequences=False,\n",
    "            name='LSTM_TI')(TI_embedding_layer)\n",
    "\n",
    "TI_deep = Dense(300, activation=None)(TI_deep)\n",
    "TI_deep = Dropout(dropout_pct)(TI_deep)\n",
    "TI_deep = BatchNormalization()(TI_deep)\n",
    "TI_deep = ELU()(TI_deep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Creating LSTM deep layer for Abstract Embeddings<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.46 s, sys: 6.4 s, total: 9.86 s\n",
      "Wall time: 791 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Abstract \n",
    "sequence_len =100\n",
    "dropout_pct =  0.3\n",
    "\n",
    "AB_embedding_layer_input = Input(shape=(sequence_len,), name='AB_embed_input')\n",
    "AB_embedding_layer = Embedding(input_dim=len(AB_tokenizer.word_index) + 1,\n",
    "                        output_dim=100, # Dimension of the dense embedding\n",
    "                        weights=[AB_embeddings_matrix],\n",
    "                        input_length=100)(AB_embedding_layer_input)\n",
    "\n",
    "lstm_size = 64\n",
    "AB_deep = LSTM(lstm_size,\n",
    "            dropout=dropout_pct,\n",
    "            recurrent_dropout=dropout_pct,\n",
    "            return_sequences=False,\n",
    "            name='LSTM_AB')(AB_embedding_layer)\n",
    "\n",
    "AB_deep = Dense(300, activation=None)(AB_deep)\n",
    "AB_deep = Dropout(dropout_pct)(AB_deep)\n",
    "AB_deep = BatchNormalization()(AB_deep)\n",
    "AB_deep = ELU()(AB_deep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Creating LSTM deep layer for TECHNICAL-Field Embeddings<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.54 s, sys: 6.37 s, total: 9.9 s\n",
      "Wall time: 744 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#TECHNICAL-Field \n",
    "sequence_len =30\n",
    "dropout_pct =  0.3\n",
    "\n",
    "TECHF_embedding_layer_input = Input(shape=(sequence_len,), name='TECHF_embed_input')\n",
    "TECHF_embedding_layer = Embedding(input_dim=len(TECHF_tokenizer.word_index) + 1,\n",
    "                        output_dim=30, # Dimension of the dense embedding\n",
    "                        weights=[TECHF_embeddings_matrix],\n",
    "                        input_length=30)(TECHF_embedding_layer_input)\n",
    "\n",
    "lstm_size = 64\n",
    "TECHF_deep = LSTM(lstm_size,\n",
    "            dropout=dropout_pct,\n",
    "            recurrent_dropout=dropout_pct,\n",
    "            return_sequences=False,\n",
    "            name='LSTM_TECHF')(TECHF_embedding_layer)\n",
    "\n",
    "TECHF_deep = Dense(300, activation=None)(TECHF_deep)\n",
    "TECHF_deep = Dropout(dropout_pct)(TECHF_deep)\n",
    "TECHF_deep = BatchNormalization()(TECHF_deep)\n",
    "TECHF_deep = ELU()(TECHF_deep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Creating LSTM deep layer for BACKGROUND Embeddings<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.76 s, sys: 7.53 s, total: 14.3 s\n",
      "Wall time: 5.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#BACKGROUND \n",
    "sequence_len =100\n",
    "dropout_pct =  0.3\n",
    "\n",
    "BACKG_embedding_layer_input = Input(shape=(sequence_len,), name='BACKG_embed_input')\n",
    "BACKG_embedding_layer = Embedding(input_dim=len(BACKG_tokenizer.word_index) + 1,\n",
    "                        output_dim=100, # Dimension of the dense embedding\n",
    "                        weights=[BACKG_embeddings_matrix],\n",
    "                        input_length=100)(BACKG_embedding_layer_input)\n",
    "\n",
    "lstm_size = 64\n",
    "BACKG_deep = LSTM(lstm_size,\n",
    "            dropout=dropout_pct,\n",
    "            recurrent_dropout=dropout_pct,\n",
    "            return_sequences=False,\n",
    "            name='LSTM_BACK')(BACKG_embedding_layer)\n",
    "\n",
    "BACKG_deep = Dense(300, activation=None)(BACKG_deep)\n",
    "BACKG_deep = Dropout(dropout_pct)(BACKG_deep)\n",
    "BACKG_deep = BatchNormalization()(BACKG_deep)\n",
    "BACKG_deep = ELU()(BACKG_deep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Creating LSTM deep layer for Summary Embeddings<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.74 s, sys: 6.75 s, total: 10.5 s\n",
      "Wall time: 1.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#SUMMARY\n",
    "sequence_len =100\n",
    "dropout_pct =  0.3\n",
    "\n",
    "SUMM_embedding_layer_input = Input(shape=(sequence_len,), name='SUMM_embed_input')\n",
    "SUMM_embedding_layer = Embedding(input_dim=len(SUMM_tokenizer.word_index) + 1,\n",
    "                        output_dim=100, # Dimension of the dense embedding\n",
    "                        weights=[SUMM_embeddings_matrix],\n",
    "                        input_length=100)(SUMM_embedding_layer_input)\n",
    "\n",
    "lstm_size = 64\n",
    "SUMM_deep = LSTM(lstm_size,\n",
    "            dropout=dropout_pct,\n",
    "            recurrent_dropout=dropout_pct,\n",
    "            return_sequences=False,\n",
    "            name='LSTM_SUMM')(SUMM_embedding_layer)\n",
    "\n",
    "SUMM_deep = Dense(300, activation=None)(SUMM_deep)\n",
    "SUMM_deep = Dropout(dropout_pct)(SUMM_deep)\n",
    "SUMM_deep = BatchNormalization()(SUMM_deep)\n",
    "SUMM_deep = ELU()(SUMM_deep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Creating LSTM deep layer for Independent Claim Embeddings<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.66 s, sys: 6.42 s, total: 10.1 s\n",
      "Wall time: 1.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#CLAIMS \n",
    "sequence_len =100\n",
    "dropout_pct =  0.4\n",
    "\n",
    "\n",
    "CLMS_embedding_layer_input = Input(shape=(sequence_len,), name='CLMS_embed_input')\n",
    "CLMS_embedding_layer = Embedding(input_dim=len(CLMS_tokenizer.word_index) + 1,\n",
    "                        output_dim=100, # Dimension of the dense embedding\n",
    "                        weights=[CLMS_embeddings_matrix],\n",
    "                        input_length=100)(CLMS_embedding_layer_input)\n",
    "\n",
    "lstm_size = 64\n",
    "CLMS_deep = LSTM(lstm_size,\n",
    "            dropout=dropout_pct,\n",
    "            recurrent_dropout=dropout_pct,\n",
    "            return_sequences=False,\n",
    "            name='LSTM_CLMS')(CLMS_embedding_layer)\n",
    "\n",
    "CLMS_deep = Dense(300, activation=None)(CLMS_deep)\n",
    "CLMS_deep = Dropout(dropout_pct)(CLMS_deep)\n",
    "CLMS_deep = BatchNormalization()(CLMS_deep)\n",
    "CLMS_deep = ELU()(CLMS_deep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Creating LSTM deep layers for one-hot vectors of Inventors and Assignees<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pa_input and inv_input layers are finished\n"
     ]
    }
   ],
   "source": [
    "dropout_pct =  0.3\n",
    "pa_input = Input(shape=(train_pa_one_hot.shape[1],), name='pa_input') \n",
    "pas = Dense(32,input_dim=train_pa_one_hot.shape[1], activation=None)(pa_input) \n",
    "pas = Dropout(dropout_pct)(pas)\n",
    "pas = BatchNormalization()(pas)\n",
    "pas = ELU()(pas)\n",
    "\n",
    "#inv\n",
    "inv_input = Input(shape=(train_inv_one_hot.shape[1],), name='inv_input') \n",
    "invs = Dense(32,input_dim=train_inv_one_hot.shape[1], activation=None)(pa_input) \n",
    "invs = Dropout(dropout_pct)(invs)\n",
    "invs = BatchNormalization()(invs)\n",
    "\n",
    "print('pa_input and inv_input layers are finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "The following cells specify the neural network architecture and hyperparameters.\n",
    "\n",
    "The model is generally composed of:\n",
    "\n",
    "contacting sequential word embeddings ofpatent text segments into a fully-connected layer\n",
    "Compile the  the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "TI_embed_input (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "AB_embed_input (InputLayer)     (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "TECHF_embed_input (InputLayer)  (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "BACKG_embed_input (InputLayer)  (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "SUMM_embed_input (InputLayer)   (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CLMS_embed_input (InputLayer)   (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20, 20)       914260      TI_embed_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 100, 100)     15446600    AB_embed_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 30, 30)       4662210     TECHF_embed_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 100, 100)     76639500    BACKG_embed_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 100, 100)     68039700    SUMM_embed_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 100, 100)     15204100    CLMS_embed_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_TI (LSTM)                  (None, 64)           21760       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_AB (LSTM)                  (None, 64)           42240       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_TECHF (LSTM)               (None, 64)           24320       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_BACK (LSTM)                (None, 64)           42240       embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_SUMM (LSTM)                (None, 64)           42240       embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_CLMS (LSTM)                (None, 64)           42240       embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 300)          19500       LSTM_TI[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 300)          19500       LSTM_AB[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 300)          19500       LSTM_TECHF[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 300)          19500       LSTM_BACK[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 300)          19500       LSTM_SUMM[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 300)          19500       LSTM_CLMS[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 300)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 300)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 300)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 300)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 300)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 300)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 300)          1200        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 300)          1200        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 300)          1200        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 300)          1200        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 300)          1200        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 300)          1200        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_1 (ELU)                     (None, 300)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "elu_2 (ELU)                     (None, 300)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "elu_3 (ELU)                     (None, 300)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "elu_4 (ELU)                     (None, 300)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "elu_5 (ELU)                     (None, 300)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "elu_6 (ELU)                     (None, 300)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenated_layer (Concatenate (None, 1800)         0           elu_1[0][0]                      \n",
      "                                                                 elu_2[0][0]                      \n",
      "                                                                 elu_3[0][0]                      \n",
      "                                                                 elu_4[0][0]                      \n",
      "                                                                 elu_5[0][0]                      \n",
      "                                                                 elu_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 128)          230528      concatenated_layer[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 128)          0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 128)          512         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_8 (ELU)                     (None, 128)          0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 42)           5418        elu_8[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 181,482,068\n",
      "Trainable params: 181,478,212\n",
      "Non-trainable params: 3,856\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras_metrics as km\n",
    "#contacting \n",
    "model_inputs_to_concat = [TI_deep, AB_deep, TECHF_deep, BACKG_deep, SUMM_deep, CLMS_deep] #invs , pas, invs\n",
    "final_layer =  Concatenate(name='concatenated_layer')(model_inputs_to_concat)\n",
    "\n",
    "output = Dense(128, activation=None)(final_layer)\n",
    "output = Dropout(dropout_pct)(output)\n",
    "output = BatchNormalization()(output)\n",
    "output = ELU()(output)\n",
    "output = Dense(num_classes, activation='sigmoid')(output)\n",
    "\n",
    "model = Model(inputs=[TI_embedding_layer_input,\n",
    "                      AB_embedding_layer_input,\n",
    "                      TECHF_embedding_layer_input,\n",
    "                      BACKG_embedding_layer_input,\n",
    "                     SUMM_embedding_layer_input,\n",
    "                     CLMS_embedding_layer_input,\n",
    "                     ],\n",
    "              outputs=output, name='model')\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy', km.categorical_precision(), km.categorical_recall()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train / Fit the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 363353 samples, validate on 40373 samples\n",
      "Epoch 1/20\n",
      "363353/363353 [==============================] - 234s 645us/step - loss: 2.1174 - acc: 0.4668 - precision: 0.0544 - recall: 0.4532 - val_loss: 1.4309 - val_acc: 0.5763 - val_precision: 0.2264 - val_recall: 0.5767\n",
      "Epoch 2/20\n",
      "363353/363353 [==============================] - 225s 620us/step - loss: 1.4617 - acc: 0.5754 - precision: 0.2742 - recall: 0.4366 - val_loss: 1.3037 - val_acc: 0.6040 - val_precision: 0.2569 - val_recall: 0.7522\n",
      "Epoch 3/20\n",
      "363353/363353 [==============================] - 221s 609us/step - loss: 1.3580 - acc: 0.5978 - precision: 0.3420 - recall: 0.4350 - val_loss: 1.2414 - val_acc: 0.6108 - val_precision: 0.2933 - val_recall: 0.7566\n",
      "Epoch 4/20\n",
      "363353/363353 [==============================] - 222s 610us/step - loss: 1.3011 - acc: 0.6083 - precision: 0.3827 - recall: 0.4097 - val_loss: 1.2194 - val_acc: 0.6165 - val_precision: 0.3459 - val_recall: 0.7035\n",
      "Epoch 5/20\n",
      "363353/363353 [==============================] - 221s 607us/step - loss: 1.2671 - acc: 0.6147 - precision: 0.4052 - recall: 0.3867 - val_loss: 1.1997 - val_acc: 0.6179 - val_precision: 0.3396 - val_recall: 0.7153\n",
      "Epoch 6/20\n",
      "363353/363353 [==============================] - 220s 605us/step - loss: 1.2375 - acc: 0.6216 - precision: 0.4358 - recall: 0.3564 - val_loss: 1.1707 - val_acc: 0.6290 - val_precision: 0.3779 - val_recall: 0.6504\n",
      "Epoch 7/20\n",
      "363353/363353 [==============================] - 225s 619us/step - loss: 1.2123 - acc: 0.6265 - precision: 0.4401 - recall: 0.3611 - val_loss: 1.1592 - val_acc: 0.6320 - val_precision: 0.3697 - val_recall: 0.7050\n",
      "Epoch 8/20\n",
      "363353/363353 [==============================] - 222s 611us/step - loss: 1.1933 - acc: 0.6314 - precision: 0.4648 - recall: 0.3632 - val_loss: 1.1620 - val_acc: 0.6268 - val_precision: 0.3783 - val_recall: 0.7198\n",
      "Epoch 9/20\n",
      "363353/363353 [==============================] - 225s 618us/step - loss: 1.1776 - acc: 0.6360 - precision: 0.4773 - recall: 0.3544 - val_loss: 1.1381 - val_acc: 0.6345 - val_precision: 0.3878 - val_recall: 0.7212\n",
      "Epoch 10/20\n",
      "363353/363353 [==============================] - 223s 613us/step - loss: 1.1596 - acc: 0.6402 - precision: 0.4875 - recall: 0.3609 - val_loss: 1.1230 - val_acc: 0.6399 - val_precision: 0.3904 - val_recall: 0.7227\n",
      "Epoch 11/20\n",
      "363353/363353 [==============================] - 223s 613us/step - loss: 1.1450 - acc: 0.6440 - precision: 0.4949 - recall: 0.3663 - val_loss: 1.1133 - val_acc: 0.6423 - val_precision: 0.3757 - val_recall: 0.7581\n",
      "Epoch 12/20\n",
      "363353/363353 [==============================] - 226s 621us/step - loss: 1.1314 - acc: 0.6480 - precision: 0.5122 - recall: 0.3632 - val_loss: 1.1073 - val_acc: 0.6442 - val_precision: 0.4298 - val_recall: 0.6549\n",
      "Epoch 13/20\n",
      "363353/363353 [==============================] - 229s 631us/step - loss: 1.1167 - acc: 0.6511 - precision: 0.5131 - recall: 0.3404 - val_loss: 1.1026 - val_acc: 0.6464 - val_precision: 0.4246 - val_recall: 0.6681\n",
      "Epoch 14/20\n",
      "363353/363353 [==============================] - 230s 634us/step - loss: 1.1039 - acc: 0.6540 - precision: 0.5232 - recall: 0.3583 - val_loss: 1.0906 - val_acc: 0.6518 - val_precision: 0.4162 - val_recall: 0.7035\n",
      "Epoch 15/20\n",
      "363353/363353 [==============================] - 238s 656us/step - loss: 1.0918 - acc: 0.6574 - precision: 0.5192 - recall: 0.3629 - val_loss: 1.0854 - val_acc: 0.6527 - val_precision: 0.4028 - val_recall: 0.7330\n",
      "Epoch 16/20\n",
      "363353/363353 [==============================] - 236s 648us/step - loss: 1.0822 - acc: 0.6597 - precision: 0.5275 - recall: 0.3860 - val_loss: 1.0820 - val_acc: 0.6561 - val_precision: 0.3995 - val_recall: 0.7153\n",
      "Epoch 17/20\n",
      "363353/363353 [==============================] - 235s 647us/step - loss: 1.0718 - acc: 0.6625 - precision: 0.5354 - recall: 0.3673 - val_loss: 1.0774 - val_acc: 0.6559 - val_precision: 0.4364 - val_recall: 0.6785\n",
      "Epoch 18/20\n",
      "363353/363353 [==============================] - 234s 644us/step - loss: 1.0620 - acc: 0.6658 - precision: 0.5446 - recall: 0.3862 - val_loss: 1.0757 - val_acc: 0.6532 - val_precision: 0.4152 - val_recall: 0.7257\n",
      "Epoch 19/20\n",
      "363353/363353 [==============================] - 235s 646us/step - loss: 1.0541 - acc: 0.6675 - precision: 0.5409 - recall: 0.3847 - val_loss: 1.0754 - val_acc: 0.6548 - val_precision: 0.4029 - val_recall: 0.7257\n",
      "Epoch 20/20\n",
      "363353/363353 [==============================] - 232s 639us/step - loss: 1.0452 - acc: 0.6704 - precision: 0.5664 - recall: 0.3665 - val_loss: 1.0660 - val_acc: 0.6563 - val_precision: 0.4203 - val_recall: 0.7271\n",
      "CPU times: user 2h 25min 27s, sys: 22min 15s, total: 2h 47min 42s\n",
      "Wall time: 1h 16min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size= 1000 \n",
    "num_epochs = 20\n",
    "\n",
    "history = model.fit(x={'TI_embed_input': TI_train,\n",
    "                       'AB_embed_input': AB_train,\n",
    "             'TECHF_embed_input': TECHF_train,\n",
    "             'BACKG_embed_input': BACKG_train,\n",
    "             'SUMM_embed_input': SUMM_train,\n",
    "             'CLMS_embed_input': CLMS_train\n",
    "             \n",
    "            },\n",
    "          y=y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epochs,\n",
    "          validation_data=\n",
    "          ({'TI_embed_input': TI_test,\n",
    "            'AB_embed_input': AB_test,\n",
    "            'TECHF_embed_input': TECHF_test,\n",
    "             'BACKG_embed_input': BACKG_test,\n",
    "             'SUMM_embed_input': SUMM_test,\n",
    "            'CLMS_embed_input': CLMS_test\n",
    "            },\n",
    "           y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Train the neural network on  multichannel inputs namely deep layers of patent text segments \n",
    " and deep layers of patent metadata.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "TI_embed_input (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "AB_embed_input (InputLayer)     (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "TECHF_embed_input (InputLayer)  (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "BACKG_embed_input (InputLayer)  (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "SUMM_embed_input (InputLayer)   (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CLMS_embed_input (InputLayer)   (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20, 20)       914260      TI_embed_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 100, 100)     15446600    AB_embed_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 30, 30)       4662210     TECHF_embed_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 100, 100)     76639500    BACKG_embed_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 100, 100)     68039700    SUMM_embed_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 100, 100)     15204100    CLMS_embed_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_TI (LSTM)                  (None, 64)           21760       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_AB (LSTM)                  (None, 64)           42240       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_TECHF (LSTM)               (None, 64)           24320       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_BACK (LSTM)                (None, 64)           42240       embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_SUMM (LSTM)                (None, 64)           42240       embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_CLMS (LSTM)                (None, 64)           42240       embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "pa_input (InputLayer)           (None, 2000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 300)          19500       LSTM_TI[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 300)          19500       LSTM_AB[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 300)          19500       LSTM_TECHF[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 300)          19500       LSTM_BACK[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 300)          19500       LSTM_SUMM[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 300)          19500       LSTM_CLMS[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 32)           64032       pa_input[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 300)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 300)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 300)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 300)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 300)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 300)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 32)           64032       pa_input[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 300)          1200        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 300)          1200        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 300)          1200        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 300)          1200        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 300)          1200        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 300)          1200        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32)           128         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu_1 (ELU)                     (None, 300)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "elu_2 (ELU)                     (None, 300)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "elu_3 (ELU)                     (None, 300)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "elu_4 (ELU)                     (None, 300)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "elu_5 (ELU)                     (None, 300)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "elu_6 (ELU)                     (None, 300)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "elu_7 (ELU)                     (None, 32)           0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32)           128         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenated_layer (Concatenate (None, 1864)         0           elu_1[0][0]                      \n",
      "                                                                 elu_2[0][0]                      \n",
      "                                                                 elu_3[0][0]                      \n",
      "                                                                 elu_4[0][0]                      \n",
      "                                                                 elu_5[0][0]                      \n",
      "                                                                 elu_6[0][0]                      \n",
      "                                                                 elu_7[0][0]                      \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 128)          238720      concatenated_layer[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 128)          0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 128)          512         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "elu_10 (ELU)                    (None, 128)          0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 42)           5418        elu_10[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 181,618,580\n",
      "Trainable params: 181,614,596\n",
      "Non-trainable params: 3,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras_metrics as km\n",
    "\n",
    "#contacting two input models\n",
    "model_inputs_to_concat = [TI_deep, AB_deep, TECHF_deep, BACKG_deep, SUMM_deep, CLMS_deep, pas, invs] \n",
    "final_layer =  Concatenate(name='concatenated_layer')(model_inputs_to_concat)\n",
    "\n",
    "output = Dense(128, activation=None)(final_layer)\n",
    "output = Dropout(dropout_pct)(output)\n",
    "output = BatchNormalization()(output)\n",
    "output = ELU()(output)\n",
    "output = Dense(num_classes, activation='sigmoid')(output)\n",
    "\n",
    "model2 =Model(inputs=[ TI_embedding_layer_input,\n",
    "                      AB_embedding_layer_input,\n",
    "                      TECHF_embedding_layer_input,\n",
    "                      BACKG_embedding_layer_input,\n",
    "                     SUMM_embedding_layer_input,\n",
    "                     CLMS_embedding_layer_input,\n",
    "                     pa_input,\n",
    "                      inv_input],\n",
    "              outputs=output, name='model')\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                       metrics=['accuracy', km.categorical_precision(), km.categorical_recall()])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model/network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 363353 samples, validate on 40373 samples\n",
      "Epoch 1/10\n",
      "363353/363353 [==============================] - 306s 842us/step - loss: 1.5099 - acc: 0.6580 - precision: 0.0953 - recall: 0.7308 - val_loss: 1.0988 - val_acc: 0.6680 - val_precision: 0.4294 - val_recall: 0.7448\n",
      "Epoch 2/10\n",
      "363353/363353 [==============================] - 289s 795us/step - loss: 0.9267 - acc: 0.7100 - precision: 0.5445 - recall: 0.5696 - val_loss: 1.0764 - val_acc: 0.6687 - val_precision: 0.4055 - val_recall: 0.7876\n",
      "Epoch 3/10\n",
      "363353/363353 [==============================] - 292s 805us/step - loss: 0.8939 - acc: 0.7165 - precision: 0.5801 - recall: 0.5254 - val_loss: 1.0814 - val_acc: 0.6704 - val_precision: 0.4621 - val_recall: 0.6932\n",
      "Epoch 4/10\n",
      "363353/363353 [==============================] - 290s 797us/step - loss: 0.8745 - acc: 0.7199 - precision: 0.5860 - recall: 0.5117 - val_loss: 1.0844 - val_acc: 0.6672 - val_precision: 0.4615 - val_recall: 0.7080\n",
      "Epoch 5/10\n",
      "363353/363353 [==============================] - 288s 792us/step - loss: 0.8591 - acc: 0.7246 - precision: 0.6064 - recall: 0.5002 - val_loss: 1.0876 - val_acc: 0.6651 - val_precision: 0.4582 - val_recall: 0.7109\n",
      "Epoch 6/10\n",
      "363353/363353 [==============================] - 287s 791us/step - loss: 0.8484 - acc: 0.7260 - precision: 0.6190 - recall: 0.4791 - val_loss: 1.0796 - val_acc: 0.6667 - val_precision: 0.4158 - val_recall: 0.7507\n",
      "Epoch 7/10\n",
      "363353/363353 [==============================] - 296s 814us/step - loss: 0.8367 - acc: 0.7306 - precision: 0.6248 - recall: 0.4697 - val_loss: 1.0897 - val_acc: 0.6614 - val_precision: 0.4214 - val_recall: 0.7507\n",
      "Epoch 8/10\n",
      "363353/363353 [==============================] - 296s 815us/step - loss: 0.8270 - acc: 0.7325 - precision: 0.6418 - recall: 0.4552 - val_loss: 1.0987 - val_acc: 0.6617 - val_precision: 0.4661 - val_recall: 0.6903\n",
      "Epoch 9/10\n",
      "363353/363353 [==============================] - 288s 792us/step - loss: 0.8190 - acc: 0.7343 - precision: 0.6298 - recall: 0.4640 - val_loss: 1.0967 - val_acc: 0.6652 - val_precision: 0.4665 - val_recall: 0.6888\n",
      "Epoch 10/10\n",
      "363353/363353 [==============================] - 289s 796us/step - loss: 0.8116 - acc: 0.7367 - precision: 0.6498 - recall: 0.4707 - val_loss: 1.0991 - val_acc: 0.6630 - val_precision: 0.4622 - val_recall: 0.6844\n",
      "CPU times: user 1h 56min 47s, sys: 20min 39s, total: 2h 17min 26s\n",
      "Wall time: 49min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size= 1000 \n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "history2 = model2.fit(x={'TI_embed_input': TI_train,\n",
    "                         'AB_embed_input': AB_train,\n",
    "             'TECHF_embed_input': TECHF_train,\n",
    "             'BACKG_embed_input': BACKG_train,\n",
    "             'SUMM_embed_input': SUMM_train,\n",
    "             'CLMS_embed_input': CLMS_train,\n",
    "             'pa_input': train_pa_one_hot,\n",
    "             'inv_input': train_inv_one_hot\n",
    "            },\n",
    "          y=y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epochs,\n",
    "          validation_data=\n",
    "          ({'TI_embed_input': TI_test,\n",
    "            'AB_embed_input': AB_test,\n",
    "            'TECHF_embed_input': TECHF_test,\n",
    "             'BACKG_embed_input': BACKG_test,\n",
    "             'SUMM_embed_input': SUMM_test,\n",
    "            'CLMS_embed_input': CLMS_test,\n",
    "            'pa_input': test_pa_one_hot,\n",
    "            'inv_input': test_inv_one_hot\n",
    "            },\n",
    "           y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Train the neural network on  multichannel inputs namely deep layers of Title and Technical Field.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "TI_embed_input (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "TECHF_embed_input (InputLayer)  (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20, 20)       914260      TI_embed_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 30, 30)       4662210     TECHF_embed_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_TI (LSTM)                  (None, 64)           21760       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_TECHF (LSTM)               (None, 64)           24320       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 300)          19500       LSTM_TI[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 300)          19500       LSTM_TECHF[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 300)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 300)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 300)          1200        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 300)          1200        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_1 (ELU)                     (None, 300)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "elu_3 (ELU)                     (None, 300)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenated_layer (Concatenate (None, 600)          0           elu_1[0][0]                      \n",
      "                                                                 elu_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 64)           38464       concatenated_layer[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 64)           0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64)           256         dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "elu_11 (ELU)                    (None, 64)           0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 42)           2730        elu_11[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 5,705,400\n",
      "Trainable params: 5,704,072\n",
      "Non-trainable params: 1,328\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#contacting two input models\n",
    "model_inputs_to_concat = [TI_deep,  TECHF_deep] #invs , pas, invs\n",
    "final_layer =  Concatenate(name='concatenated_layer')(model_inputs_to_concat)\n",
    "\n",
    "output = Dense(64, activation=None)(final_layer)\n",
    "output = Dropout(dropout_pct)(output)\n",
    "output = BatchNormalization()(output)\n",
    "output = ELU()(output)\n",
    "output = Dense(num_classes, activation='sigmoid')(output)\n",
    "\n",
    "model3 =Model(inputs=[ TI_embedding_layer_input,\n",
    "                      TECHF_embedding_layer_input\n",
    "                      ],\n",
    "              outputs=output, name='model')\n",
    "model3.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                       metrics=['accuracy', km.categorical_precision(), km.categorical_recall()])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Fit the model <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 363353 samples, validate on 40373 samples\n",
      "Epoch 1/10\n",
      "363353/363353 [==============================] - 31s 86us/step - loss: 2.0806 - acc: 0.5398 - precision: 0.0570 - recall: 0.6855 - val_loss: 1.4180 - val_acc: 0.5989 - val_precision: 0.2578 - val_recall: 0.6077\n",
      "Epoch 2/10\n",
      "363353/363353 [==============================] - 26s 71us/step - loss: 1.4311 - acc: 0.5970 - precision: 0.3425 - recall: 0.4566 - val_loss: 1.3698 - val_acc: 0.6009 - val_precision: 0.2964 - val_recall: 0.6313\n",
      "Epoch 3/10\n",
      "363353/363353 [==============================] - 25s 70us/step - loss: 1.3923 - acc: 0.6019 - precision: 0.4039 - recall: 0.4379 - val_loss: 1.3576 - val_acc: 0.5997 - val_precision: 0.3446 - val_recall: 0.5885\n",
      "Epoch 4/10\n",
      "363353/363353 [==============================] - 26s 70us/step - loss: 1.3739 - acc: 0.6036 - precision: 0.4367 - recall: 0.3838 - val_loss: 1.3461 - val_acc: 0.6010 - val_precision: 0.3758 - val_recall: 0.5310\n",
      "Epoch 5/10\n",
      "363353/363353 [==============================] - 26s 70us/step - loss: 1.3599 - acc: 0.6064 - precision: 0.4656 - recall: 0.3639 - val_loss: 1.3371 - val_acc: 0.6021 - val_precision: 0.3789 - val_recall: 0.5442\n",
      "Epoch 6/10\n",
      "363353/363353 [==============================] - 26s 71us/step - loss: 1.3498 - acc: 0.6077 - precision: 0.4712 - recall: 0.3244 - val_loss: 1.3341 - val_acc: 0.6005 - val_precision: 0.3491 - val_recall: 0.5782\n",
      "Epoch 7/10\n",
      "363353/363353 [==============================] - 26s 71us/step - loss: 1.3409 - acc: 0.6087 - precision: 0.4724 - recall: 0.3171 - val_loss: 1.3294 - val_acc: 0.6024 - val_precision: 0.3793 - val_recall: 0.5398\n",
      "Epoch 8/10\n",
      "363353/363353 [==============================] - 26s 72us/step - loss: 1.3327 - acc: 0.6106 - precision: 0.4848 - recall: 0.3140 - val_loss: 1.3244 - val_acc: 0.6030 - val_precision: 0.3991 - val_recall: 0.5221\n",
      "Epoch 9/10\n",
      "363353/363353 [==============================] - 26s 71us/step - loss: 1.3266 - acc: 0.6124 - precision: 0.5009 - recall: 0.3122 - val_loss: 1.3200 - val_acc: 0.6041 - val_precision: 0.4080 - val_recall: 0.5103\n",
      "Epoch 10/10\n",
      "363353/363353 [==============================] - 25s 70us/step - loss: 1.3212 - acc: 0.6129 - precision: 0.4892 - recall: 0.3128 - val_loss: 1.3226 - val_acc: 0.6023 - val_precision: 0.4038 - val_recall: 0.5295\n",
      "CPU times: user 8min 25s, sys: 1min, total: 9min 26s\n",
      "Wall time: 4min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size= 1000 \n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "history3 = model3.fit(x={'TI_embed_input': TI_train,\n",
    "             'TECHF_embed_input': TECHF_train\n",
    "            },\n",
    "          y=y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epochs,\n",
    "          validation_data=\n",
    "          ({'TI_embed_input': TI_test,\n",
    "            'TECHF_embed_input': TECHF_test\n",
    "            },\n",
    "           y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Train the neural network on  multichannel inputs namely deep layers of Title, abstrcat and Technical Field.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "TI_embed_input (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "AB_embed_input (InputLayer)     (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "TECHF_embed_input (InputLayer)  (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20, 20)       914260      TI_embed_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 100, 100)     15446600    AB_embed_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 30, 30)       4662210     TECHF_embed_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_TI (LSTM)                  (None, 64)           21760       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_AB (LSTM)                  (None, 64)           42240       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_TECHF (LSTM)               (None, 64)           24320       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 300)          19500       LSTM_TI[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 300)          19500       LSTM_AB[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 300)          19500       LSTM_TECHF[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 300)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 300)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 300)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 300)          1200        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 300)          1200        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 300)          1200        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_1 (ELU)                     (None, 300)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "elu_2 (ELU)                     (None, 300)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "elu_3 (ELU)                     (None, 300)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenated_layer (Concatenate (None, 900)          0           elu_1[0][0]                      \n",
      "                                                                 elu_2[0][0]                      \n",
      "                                                                 elu_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 128)          115328      concatenated_layer[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 128)          0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128)          512         dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "elu_12 (ELU)                    (None, 128)          0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 42)           5418        elu_12[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 21,294,748\n",
      "Trainable params: 21,292,692\n",
      "Non-trainable params: 2,056\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras_metrics as km\n",
    "#contacting two input models\n",
    "model_inputs_to_concat = [TI_deep, AB_deep, TECHF_deep] #invs , pas, invs\n",
    "final_layer =  Concatenate(name='concatenated_layer')(model_inputs_to_concat)\n",
    "\n",
    "output = Dense(128, activation=None)(final_layer)\n",
    "output = Dropout(dropout_pct)(output)\n",
    "output = BatchNormalization()(output)\n",
    "output = ELU()(output)\n",
    "output = Dense(num_classes, activation='sigmoid')(output)\n",
    "\n",
    "model4 = Model(inputs=[TI_embedding_layer_input,\n",
    "                      AB_embedding_layer_input,\n",
    "                      TECHF_embedding_layer_input\n",
    "                     ],\n",
    "              outputs=output, name='model')\n",
    "model4.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                       metrics=['accuracy', km.categorical_precision(), km.categorical_recall()])\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Fit the model <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 363353 samples, validate on 40373 samples\n",
      "Epoch 1/10\n",
      "363353/363353 [==============================] - 85s 233us/step - loss: 1.7639 - acc: 0.5874 - precision: 0.0978 - recall: 0.6676 - val_loss: 1.2810 - val_acc: 0.6221 - val_precision: 0.3321 - val_recall: 0.6386\n",
      "Epoch 2/10\n",
      "363353/363353 [==============================] - 77s 212us/step - loss: 1.2674 - acc: 0.6251 - precision: 0.4109 - recall: 0.5129 - val_loss: 1.2499 - val_acc: 0.6228 - val_precision: 0.3627 - val_recall: 0.6195\n",
      "Epoch 3/10\n",
      "363353/363353 [==============================] - 77s 211us/step - loss: 1.2374 - acc: 0.6298 - precision: 0.4551 - recall: 0.4477 - val_loss: 1.2355 - val_acc: 0.6254 - val_precision: 0.3602 - val_recall: 0.6268\n",
      "Epoch 4/10\n",
      "363353/363353 [==============================] - 78s 213us/step - loss: 1.2186 - acc: 0.6332 - precision: 0.4769 - recall: 0.4159 - val_loss: 1.2249 - val_acc: 0.6228 - val_precision: 0.3630 - val_recall: 0.6195\n",
      "Epoch 5/10\n",
      "363353/363353 [==============================] - 77s 212us/step - loss: 1.2030 - acc: 0.6363 - precision: 0.4939 - recall: 0.3953 - val_loss: 1.2132 - val_acc: 0.6233 - val_precision: 0.3862 - val_recall: 0.5782\n",
      "Epoch 6/10\n",
      "363353/363353 [==============================] - 77s 211us/step - loss: 1.1908 - acc: 0.6377 - precision: 0.4994 - recall: 0.3820 - val_loss: 1.2007 - val_acc: 0.6275 - val_precision: 0.3868 - val_recall: 0.5723\n",
      "Epoch 7/10\n",
      "363353/363353 [==============================] - 77s 213us/step - loss: 1.1771 - acc: 0.6404 - precision: 0.5021 - recall: 0.3844 - val_loss: 1.1944 - val_acc: 0.6269 - val_precision: 0.3795 - val_recall: 0.5900\n",
      "Epoch 8/10\n",
      "363353/363353 [==============================] - 77s 211us/step - loss: 1.1639 - acc: 0.6438 - precision: 0.5104 - recall: 0.3732 - val_loss: 1.1851 - val_acc: 0.6284 - val_precision: 0.3947 - val_recall: 0.5693\n",
      "Epoch 9/10\n",
      "363353/363353 [==============================] - 78s 213us/step - loss: 1.1534 - acc: 0.6455 - precision: 0.5174 - recall: 0.3758 - val_loss: 1.1761 - val_acc: 0.6307 - val_precision: 0.4055 - val_recall: 0.5442\n",
      "Epoch 10/10\n",
      "363353/363353 [==============================] - 78s 214us/step - loss: 1.1442 - acc: 0.6471 - precision: 0.5235 - recall: 0.3520 - val_loss: 1.1743 - val_acc: 0.6283 - val_precision: 0.4094 - val_recall: 0.5398\n",
      "CPU times: user 23min 22s, sys: 2min 49s, total: 26min 12s\n",
      "Wall time: 13min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size= 1000 \n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "history4 = model4.fit(x={'TI_embed_input': TI_train,\n",
    "                         'AB_embed_input': AB_train,\n",
    "             'TECHF_embed_input': TECHF_train\n",
    "            },\n",
    "          y=y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epochs,\n",
    "          validation_data=\n",
    "          ({'TI_embed_input': TI_test,\n",
    "            'AB_embed_input': AB_test,\n",
    "            'TECHF_embed_input': TECHF_test\n",
    "            },\n",
    "           y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Train the neural network on  multichannel inputs namely deep layers of Title, Technical Field, Inventors, and Assignees.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "TI_embed_input (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "TECHF_embed_input (InputLayer)  (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20, 20)       914260      TI_embed_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 30, 30)       4662210     TECHF_embed_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_TI (LSTM)                  (None, 64)           21760       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_TECHF (LSTM)               (None, 64)           24320       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "pa_input (InputLayer)           (None, 2000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 300)          19500       LSTM_TI[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 300)          19500       LSTM_TECHF[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 32)           64032       pa_input[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 300)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 300)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 32)           64032       pa_input[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 300)          1200        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 300)          1200        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32)           128         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu_1 (ELU)                     (None, 300)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "elu_3 (ELU)                     (None, 300)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "elu_7 (ELU)                     (None, 32)           0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32)           128         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenated_layer (Concatenate (None, 664)          0           elu_1[0][0]                      \n",
      "                                                                 elu_3[0][0]                      \n",
      "                                                                 elu_7[0][0]                      \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 128)          85120       concatenated_layer[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 128)          0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 128)          512         dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "elu_13 (ELU)                    (None, 128)          0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 42)           5418        elu_13[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 5,883,320\n",
      "Trainable params: 5,881,736\n",
      "Non-trainable params: 1,584\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#contacting two input models\n",
    "model_inputs_to_concat = [TI_deep, TECHF_deep,  pas, invs] #invs , pas, invs\n",
    "final_layer =  Concatenate(name='concatenated_layer')(model_inputs_to_concat)\n",
    "\n",
    "output = Dense(128, activation=None)(final_layer)\n",
    "output = Dropout(dropout_pct)(output)\n",
    "output = BatchNormalization()(output)\n",
    "output = ELU()(output)\n",
    "output = Dense(num_classes, activation='sigmoid')(output)\n",
    "\n",
    "model5 =Model(inputs=[ TI_embedding_layer_input,\n",
    "                      TECHF_embedding_layer_input,\n",
    "                     pa_input,\n",
    "                      inv_input],\n",
    "              outputs=output, name='model')\n",
    "model5.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                       metrics=['accuracy', km.categorical_precision(), km.categorical_recall()])\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br< Fit the mode. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 363353 samples, validate on 40373 samples\n",
      "Epoch 1/10\n",
      "363353/363353 [==============================] - 38s 106us/step - loss: 1.7714 - acc: 0.5898 - precision: 0.0911 - recall: 0.6943 - val_loss: 1.2946 - val_acc: 0.6199 - val_precision: 0.3291 - val_recall: 0.6445\n",
      "Epoch 2/10\n",
      "363353/363353 [==============================] - 33s 90us/step - loss: 1.2540 - acc: 0.6284 - precision: 0.4267 - recall: 0.5499 - val_loss: 1.2791 - val_acc: 0.6155 - val_precision: 0.3236 - val_recall: 0.6534\n",
      "Epoch 3/10\n",
      "363353/363353 [==============================] - 33s 90us/step - loss: 1.2313 - acc: 0.6310 - precision: 0.4637 - recall: 0.4969 - val_loss: 1.2716 - val_acc: 0.6154 - val_precision: 0.3373 - val_recall: 0.6209\n",
      "Epoch 4/10\n",
      "363353/363353 [==============================] - 32s 89us/step - loss: 1.2190 - acc: 0.6328 - precision: 0.4732 - recall: 0.4597 - val_loss: 1.2731 - val_acc: 0.6143 - val_precision: 0.3538 - val_recall: 0.6047\n",
      "Epoch 5/10\n",
      "363353/363353 [==============================] - 33s 91us/step - loss: 1.2098 - acc: 0.6346 - precision: 0.4920 - recall: 0.4455 - val_loss: 1.2634 - val_acc: 0.6157 - val_precision: 0.3476 - val_recall: 0.6106\n",
      "Epoch 6/10\n",
      "363353/363353 [==============================] - 33s 91us/step - loss: 1.2029 - acc: 0.6356 - precision: 0.4928 - recall: 0.4292 - val_loss: 1.2619 - val_acc: 0.6175 - val_precision: 0.3870 - val_recall: 0.5811\n",
      "Epoch 7/10\n",
      "363353/363353 [==============================] - 33s 91us/step - loss: 1.1980 - acc: 0.6364 - precision: 0.5028 - recall: 0.4164 - val_loss: 1.2645 - val_acc: 0.6149 - val_precision: 0.3796 - val_recall: 0.5723\n",
      "Epoch 8/10\n",
      "363353/363353 [==============================] - 33s 92us/step - loss: 1.1925 - acc: 0.6376 - precision: 0.5125 - recall: 0.3913 - val_loss: 1.2637 - val_acc: 0.6143 - val_precision: 0.3881 - val_recall: 0.5782\n",
      "Epoch 9/10\n",
      "363353/363353 [==============================] - 34s 92us/step - loss: 1.1885 - acc: 0.6381 - precision: 0.5091 - recall: 0.4090 - val_loss: 1.2556 - val_acc: 0.6178 - val_precision: 0.3683 - val_recall: 0.5959\n",
      "Epoch 10/10\n",
      "363353/363353 [==============================] - 33s 92us/step - loss: 1.1842 - acc: 0.6386 - precision: 0.5140 - recall: 0.4033 - val_loss: 1.2581 - val_acc: 0.6173 - val_precision: 0.3764 - val_recall: 0.5885\n",
      "CPU times: user 9min 50s, sys: 1min 3s, total: 10min 53s\n",
      "Wall time: 5min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size= 1000 \n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "history5 = model5.fit(x={'TI_embed_input': TI_train,\n",
    "             'TECHF_embed_input': TECHF_train,\n",
    "             'pa_input': train_pa_one_hot,\n",
    "             'inv_input': train_inv_one_hot\n",
    "            },\n",
    "          y=y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epochs,\n",
    "          validation_data=\n",
    "          ({'TI_embed_input': TI_test,\n",
    "            'TECHF_embed_input': TECHF_test,\n",
    "            'pa_input': test_pa_one_hot,\n",
    "            'inv_input': test_inv_one_hot\n",
    "            },\n",
    "           y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
